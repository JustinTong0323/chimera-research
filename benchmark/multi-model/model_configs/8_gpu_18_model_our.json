[
    {
      "model_name": "model_10",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            0
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_12",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            0
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_1",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            0
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_11",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            1
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_3",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            1
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_13",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            1
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_2",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            2
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_4",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            2
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_5",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            2
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_15",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            3
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_16",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            3
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_14",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            3
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_6",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            4
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_18",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            4
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_8",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            4
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_7",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            5
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_9",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            5
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    },
    {
      "model_name": "model_17",
      "model_path": "meta-llama/Llama-3.2-1B",
      "tokenizer_path": "meta-llama/Llama-3.2-1B",
      "tp_size": 1,
      "init_placements": [
        {
          "gpu_ids": [
            5
          ],
          "on": true,
          "max_memory_pool_size": 15
        }
      ]
    }
  ]